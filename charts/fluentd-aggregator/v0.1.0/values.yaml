# Default values for fluentd.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
image:
  # repository: gcr.io/google-containers/fluentd-elasticsearch
  # tag: v2.3.1
  repository: guangbo/fluentd
  tag: dev
  pullPolicy: IfNotPresent
  # pullSecrets:
  #   - secret1
  #   - secret2

replicas: 1

## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: OrderedReady

## The StatefulSet Update Strategy which Kafka will use when changes are applied.
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy:
  type: "RollingUpdate"

output:
  bufferChunkLimit: "2M"
  bufferQueueLimit: "8"
  flushInterval: "5s"
  # options are elasticsearch, syslog, splunk, custom
  type: "elasticsearch"
  syslogCaFile: ""
  customConf: ""

env:
  OUTPUT_ES_HOSTS: "elasticsearch:9200"
  OUTPUT_ES_PREFIX: "k8s"
  OUTPUT_ES_DATEFORMAT: "%Y.%m.%d"
  # OUTPUT_SPLUNK_HOST:
  # OUTPUT_SPLUNK_PORT:
  # OUTPUT_SPLUNK_TOKEN:
  # OUTPUT_SPLUNK_SOURCE_TYPE:
  # OUTPUT_SPLUNK_INDEX:
  # OUTPUT_SPLUNK_ACK: false
  # OUTPUT_SPLUNK_CHANNEL:
  # OUTPUT_KAFKA_HOST_TYPE: "zookeeper"
  # OUTPUT_KAFKA_ZK_HOSTS: ""
  # OUTPUT_KAFKA_BROKER_HOSTS: ""
  # OUTPUT_KAFKA_TOPIC_KEY: topic
  # OUTPUT_KAFKA_PARTITION: partition
  # OUTPUT_KAFKA_PARTITION_KEY: partition_key
  # OUTPUT_KAFKA_MESSAGE_KEY: message_key
  # OUTPUT_SYSLOG_PROTOCOL: udp
  # OUTPUT_SYSLOG_HOST:
  # OUTPUT_SYSLOG_SEVERITY: notice
  # OUTPUT_SYSLOG_PROGRAM: fluentd
  # OUTPUT_SYSLOG_TOKEN:

service:
  type: ClusterIP
  externalPort: 80
  ports:
    - name: "prometheus"
      protocol: TCP
      containerPort: 24231
    - name: "forward-input"
      protocol: TCP
      containerPort: 24224
    - name: "input-udp"
      protocol: UDP
      containerPort: 24224
    # - name: "monitor-agent"
    #   protocol: TCP
    #   containerPort: 24220

ingress:
  enabled: false
  # Used to create an Ingress and Service record.
  # hosts:
  #   - name: "http-input.local"
  #     protocol: TCP
  #     serviceName: http-input
  #     servicePort: 9880
  annotations:
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  tls:
    # Secrets must be manually created in the namespace.
    # - secretName: http-input-tls
    #   hosts:
    #     - http-input.local

configMaps:
  general.conf: |
    # Prevent fluentd from handling records containing its own logs. Otherwise
    # it can lead to an infinite loop, when error in sending one message generates
    # another message which also fails to be sent and so on.
    <match fluentd.**>
      @type null
    </match>

    # Used for health checking
    <source>
      @type http
      port 9880
      bind 0.0.0.0
      body_size_limit 32m
      keepalive_timeout 10s
    </source>

    # Emits internal metrics to every minute, and also exposes them on port
    # 24220. Useful for determining if an output plugin is retryring/erroring,
    # or determining the buffer queue length.
    <source>
      @type monitor_agent
      bind 0.0.0.0
      port 24220
      tag fluentd.monitor.metrics
    </source>
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  monitoring.conf: |
    # expose metrics in prometheus format
    <source>
      @type prometheus
      bind 0.0.0.0
      port 24231
      metrics_path /metrics
    </source>
    <source>
      @type prometheus_output_monitor
      interval 10
      <labels>
        hostname ${hostname}
      </labels>
    </source>
    <source>
    @type prometheus_monitor
    </source>
  forward-input.conf: |
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>
resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 500m
    memory: 200Mi
  requests:
    cpu: 100m
    memory: 200Mi

## Persist data to a persistent volume of buffer
## Caution, file buffer implementation depends on the characteristics of local file system.
## Donâ€™t use file buffer on remote file system, e.g. NFS, GlusterFS, HDFS and etc. We observed major data loss by using remote file system.
persistence:
  enabled: false

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  # annotations: {}
  accessMode: ReadWriteOnce
  size: 10Gi

nodeSelector: {}

tolerations: []

affinity: {}
