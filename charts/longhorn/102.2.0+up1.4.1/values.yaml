# Default values for longhorn.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
global:
  cattle:
    systemDefaultRegistry: ""
    windowsCluster:
      # Enable this to allow Longhorn to run on the Rancher deployed Windows cluster
      enabled: false
      # Tolerate Linux node taint
      tolerations:
      - key: "cattle.io/os"
        value: "linux"
        effect: "NoSchedule"
        operator: "Equal"
      # Select Linux nodes
      nodeSelector:
        kubernetes.io/os: "linux"
      # Recognize toleration and node selector for Longhorn run-time created components
      defaultSetting:
        taintToleration: cattle.io/os=linux:NoSchedule
        systemManagedComponentsNodeSelector: kubernetes.io/os:linux

image:
  longhorn:
    engine:
      repository: rancher/mirrored-longhornio-longhorn-engine
      tag: v1.4.1
    manager:
      repository: rancher/mirrored-longhornio-longhorn-manager
      tag: v1.4.1
    ui:
      repository: rancher/mirrored-longhornio-longhorn-ui
      tag: v1.4.1
    instanceManager:
      repository: rancher/mirrored-longhornio-longhorn-instance-manager
      tag: v1.4.1
    shareManager:
      repository: rancher/mirrored-longhornio-longhorn-share-manager
      tag: v1.4.1
    backingImageManager:
      repository: rancher/mirrored-longhornio-backing-image-manager
      tag: v1.4.1
    supportBundleKit:
      repository: rancher/mirrored-longhornio-support-bundle-kit
      tag: v0.0.19
  csi:
    attacher:
      repository: rancher/mirrored-longhornio-csi-attacher
      tag: v3.4.0
    provisioner:
      repository: rancher/mirrored-longhornio-csi-provisioner
      tag: v2.1.2
    nodeDriverRegistrar:
      repository: rancher/mirrored-longhornio-csi-node-driver-registrar
      tag: v2.5.0
    resizer:
      repository: rancher/mirrored-longhornio-csi-resizer
      tag: v1.3.0
    snapshotter:
      repository: rancher/mirrored-longhornio-csi-snapshotter
      tag: v5.0.1
    livenessProbe:
      repository: rancher/mirrored-longhornio-livenessprobe
      tag: v2.8.0
  pullPolicy: IfNotPresent

service:
  ui:
    type: ClusterIP
    nodePort: null
  manager:
    type: ClusterIP
    nodePort: ""
    loadBalancerIP: ""
    loadBalancerSourceRanges: ""

persistence:
  defaultClass: true
  defaultFsType: ext4
  defaultMkfsParams: ""
  defaultClassReplicaCount: 3
  defaultDataLocality: disabled # best-effort otherwise
  reclaimPolicy: Delete
  migratable: false
  recurringJobSelector:
    enable: false
    jobList: []
  backingImage:
    enable: false
    name: ~
    dataSourceType: ~
    dataSourceParameters: ~
    expectedChecksum: ~
  defaultNodeSelector:
    enable: false # disable by default
    selector: []
  removeSnapshotsDuringFilesystemTrim: ignored # "enabled" or "disabled" otherwise

csi:
  kubeletRootDir: ~
  attacherReplicaCount: ~
  provisionerReplicaCount: ~
  resizerReplicaCount: ~
  snapshotterReplicaCount: ~

defaultSettings:
  backupTarget: ~
  backupTargetCredentialSecret: ~
  allowRecurringJobWhileVolumeDetached: ~
  createDefaultDiskLabeledNodes: ~
  defaultDataPath: ~
  defaultDataLocality: ~
  replicaSoftAntiAffinity: ~
  replicaAutoBalance: ~
  storageOverProvisioningPercentage: ~
  storageMinimalAvailablePercentage: ~
  upgradeChecker: ~
  defaultReplicaCount: ~
  defaultLonghornStaticStorageClass: ~
  backupstorePollInterval: ~
  failedBackupTTL: ~
  restoreVolumeRecurringJobs: ~
  recurringSuccessfulJobsHistoryLimit: ~
  recurringFailedJobsHistoryLimit: ~
  supportBundleFailedHistoryLimit: ~
  taintToleration: ~
  systemManagedComponentsNodeSelector: ~
  priorityClass: ~
  autoSalvage: ~
  autoDeletePodWhenVolumeDetachedUnexpectedly: ~
  disableSchedulingOnCordonedNode: ~
  replicaZoneSoftAntiAffinity: ~
  nodeDownPodDeletionPolicy: ~
  allowNodeDrainWithLastHealthyReplica: ~
  mkfsExt4Parameters: ~
  disableReplicaRebuild: ~
  replicaReplenishmentWaitInterval: ~
  concurrentReplicaRebuildPerNodeLimit: ~
  concurrentVolumeBackupRestorePerNodeLimit: ~
  disableRevisionCounter: ~
  systemManagedPodsImagePullPolicy: ~
  allowVolumeCreationWithDegradedAvailability: ~
  autoCleanupSystemGeneratedSnapshot: ~
  concurrentAutomaticEngineUpgradePerNodeLimit: ~
  backingImageCleanupWaitInterval: ~
  backingImageRecoveryWaitInterval: ~
  guaranteedEngineManagerCPU: ~
  guaranteedReplicaManagerCPU: ~
  kubernetesClusterAutoscalerEnabled: ~
  orphanAutoDeletion: ~
  storageNetwork: ~
  deletingConfirmationFlag: ~
  engineReplicaTimeout: ~
  snapshotDataIntegrity: ~
  snapshotDataIntegrityImmediateCheckAfterSnapshotCreation: ~
  snapshotDataIntegrityCronjob: ~
  removeSnapshotsDuringFilesystemTrim: ~
  fastReplicaRebuildEnabled: ~
  replicaFileSyncHttpClientTimeout: ~
privateRegistry:
  createSecret: ~
  registryUrl: ~
  registryUser: ~
  registryPasswd: ~
  registrySecret: ~

longhornManager:
  log:
    ## Allowed values are `plain` or `json`.
    format: plain
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn Manager DaemonSet, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn Manager DaemonSet, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"
  serviceAnnotations: {}
  ## If you want to set annotations for the Longhorn Manager service, delete the `{}` in the line above
  ## and uncomment this example block
  #  annotation-key1: "annotation-value1"
  #  annotation-key2: "annotation-value2"

longhornDriver:
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn Driver Deployer Deployment, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn Driver Deployer Deployment, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"

longhornUI:
  replicas: 2
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn UI Deployment, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn UI Deployment, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"

longhornConversionWebhook:
  replicas: 2
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn conversion webhook Deployment, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn conversion webhook Deployment, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"

longhornAdmissionWebhook:
  replicas: 2
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn admission webhook Deployment, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn admission webhook Deployment, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"

longhornRecoveryBackend:
  replicas: 2
  priorityClass: ~
  tolerations: []
  ## If you want to set tolerations for Longhorn recovery backend Deployment, delete the `[]` in the line above
  ## and uncomment this example block
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"
  nodeSelector: {}
  ## If you want to set node selector for Longhorn recovery backend Deployment, delete the `{}` in the line above
  ## and uncomment this example block
  #  label-key1: "label-value1"
  #  label-key2: "label-value2"

ingress:
  ## Set to true to enable ingress record generation
  enabled: false

  ## Add ingressClassName to the Ingress
  ## Can replace the kubernetes.io/ingress.class annotation on v1.18+
  ingressClassName: ~

  host: sslip.io

  ## Set this to true in order to enable TLS on the ingress record
  tls: false

  ## Enable this in order to enable that the backend service will be connected at port 443
  secureBackends: false

  ## If TLS is set to true, you must declare what secret will store the key/certificate for TLS
  tlsSecret: longhorn.local-tls

  ## If ingress is enabled you can set the default ingress path
  ## then you can access the UI by using the following full path {{host}}+{{path}}
  path: /

  ## Ingress annotations done as key:value pairs
  ## If you're using kube-lego, you will want to add:
  ## kubernetes.io/tls-acme: true
  ##
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/annotations.md
  ##
  ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
  annotations:
  #  kubernetes.io/ingress.class: nginx
  #  kubernetes.io/tls-acme: true

  secrets:
  ## If you're providing your own certificates, please use this to add the certificates as secrets
  ## key and certificate should start with -----BEGIN CERTIFICATE----- or
  ## -----BEGIN RSA PRIVATE KEY-----
  ##
  ## name should line up with a tlsSecret set further up
  ## If you're using kube-lego, this is unneeded, as it will create the secret for you if it is not set
  ##
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  # - name: longhorn.local-tls
  #   key:
  #   certificate:

#  For Kubernetes < v1.25, if your cluster enables Pod Security Policy admission controller,
#  set this to `true` to ship longhorn-psp which allow privileged Longhorn pods to start
enablePSP: false

## Specify override namespace, specifically this is useful for using longhorn as sub-chart
## and its release namespace is not the `longhorn-system`
namespaceOverride: ""

# Annotations to add to the Longhorn Manager DaemonSet Pods. Optional.
annotations: {}

serviceAccount:
  # Annotations to add to the service account
  annotations: {}
